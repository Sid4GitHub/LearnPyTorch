{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ba8eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\miniconda_env\\hf-pytorch\\lib\\site-packages\\transformers\\utils\\hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import time\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a24915e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3145df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25091a71e10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd649dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"D:\\\\Work\\wsl\\\\ML-DS\\\\fashion-mnist\\\\fashion-mnist_train.csv\")#.head(5000)\n",
    "test_df = pd.read_csv(\"D:\\\\Work\\wsl\\\\ML-DS\\\\fashion-mnist\\\\fashion-mnist_test.csv\")#.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b10caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to Numpy\n",
    "X_train = train_df.iloc[:,1:].values\n",
    "y_train = train_df.iloc[:,0].values\n",
    "\n",
    "X_test = test_df.iloc[:,1:].values\n",
    "y_test = test_df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50406ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit and transform on training set\n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ea90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        super().__init__()\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)#.to(device=device)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)#.to(device=device)\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "\n",
    "train_dataset = CustomDataset(X_train_scaled, y_train)\n",
    "test_dataset = CustomDataset(X_test_scaled, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaa9c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cls = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0708d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyANNLightning(L.LightningModule):\n",
    "    def __init__(self, num_features, num_cls, learning_rate=0.001, weight_decay=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # Your exact same model architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128), \n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),   \n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_cls)\n",
    "        )\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        batch_features, batch_labels = batch\n",
    "        outputs = self(batch_features)\n",
    "        loss = self.criterion(outputs, batch_labels)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        batch_features, batch_labels = batch\n",
    "        outputs = self(batch_features)\n",
    "        loss = self.criterion(outputs, batch_labels)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(\n",
    "            self.parameters(), \n",
    "            lr=self.hparams.learning_rate, \n",
    "            weight_decay=self.hparams.weight_decay\n",
    "        )\n",
    "        return optimizer\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        \"\"\"Apply weight initialization when training starts\"\"\"\n",
    "        def init_weights(m):\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        print(f\"Model initialized with {self.hparams.num_features} features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16959689",
   "metadata": {},
   "source": [
    "# Validation of Training Steps in PyTorch Lightning\n",
    "\n",
    "In `MyANNLightning` class, do **not** need to call  \n",
    "```python\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "```\n",
    "manually—Lightning handles these under the hood. Here is how Lightning executes each training batch:\n",
    "\n",
    "1. **`training_step`**  \n",
    "   - You compute and return the loss.  \n",
    "   - Lightning automatically:\n",
    "     - Calls `optimizer.zero_grad()` before we `training_step`.\n",
    "     - Uses the returned loss to perform `loss.backward()`.\n",
    "     - Calls `optimizer.step()` after backpropagation.\n",
    "\n",
    "2. **`configure_optimizers`**  \n",
    "   - Lightning fetches the optimizer we return here and wires it into its internal loop.  \n",
    "   - If we need learning‐rate schedulers, we can also return them in a tuple or list, and Lightning will step them appropriately.\n",
    "\n",
    "3. **Gradient Accumulation, Mixed Precision, Multi-GPU, etc.**  \n",
    "   - All boilerplate for zeroing gradients, backward passes, gradient clipping, optimizer steps, and moving between optimizers is handled automatically by Lightning’s Trainer.\n",
    "\n",
    "4. **Validation Loop**  \n",
    "   - Your `validation_step` computes and logs validation loss.  \n",
    "   - Lightning accumulates these losses across batches, but never calls backward on them (no gradient steps during validation).\n",
    "\n",
    "## Putting It All Together\n",
    "\n",
    "When  run:\n",
    "```python\n",
    "trainer = pl.Trainer(...)\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "```\n",
    "Lightning executes internally:\n",
    "\n",
    "- Loop over epochs:\n",
    "  - Loop over training batches:\n",
    "    1. `optimizer.zero_grad()`\n",
    "    2. Forward pass → your `training_step` → loss returned\n",
    "    3. `loss.backward()`\n",
    "    4. `optimizer.step()`\n",
    "    5. Logging as you’ve set (`self.log(\"train_loss\", ...)`)\n",
    "  - Loop over validation batches:\n",
    "    1. Forward pass → your `validation_step` → validation losses logged\n",
    "    2. No gradient operations\n",
    "\n",
    "we do not need to—and should not—duplicate these steps manually. Lightning’s whole purpose is to remove this boilerplate so you can focus on model logic, not optimizer bookkeeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e058c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = MyANNLightning(\n",
    "    num_features=X_train_scaled.shape[1], \n",
    "    num_cls=num_cls\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f193472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    min_delta=0.0001,\n",
    "    mode='min',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d11d25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\Work\\miniconda_env\\hf-pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=1000,                   # Maximum number of epochs to train for\n",
    "    callbacks=[early_stopping],        # Use early stopping callback to stop training when validation loss stops improving\n",
    "    accelerator='auto',                # Automatically select 'gpu', 'cpu', or other hardware accelerators if available\n",
    "    devices='auto',                    # Automatically use all available devices (e.g., all GPUs if available)\n",
    "    enable_checkpointing=False,        # Disable saving model checkpoints to disk (no files will be written)\n",
    "    deterministic=True,               # Ensure deterministic training for reproducibility when **True** (may reduce performance)\n",
    "    log_every_n_steps=1                # Log training metrics every step (very frequent logging)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2a826a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | model     | Sequential       | 243 K  | train\n",
      "1 | criterion | CrossEntropyLoss | 0      | train\n",
      "-------------------------------------------------------\n",
      "243 K     Trainable params\n",
      "0         Non-trainable params\n",
      "243 K     Total params\n",
      "0.975     Total estimated model params size (MB)\n",
      "15        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with 784 features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d8bc47586140feaaee34bda1d61d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Work\\miniconda_env\\hf-pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "d:\\Work\\miniconda_env\\hf-pytorch\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa34f62569124ccdb2757c3a2bf45463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e965f5a2cdb438daac4e5095c83705a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.403\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78804a2ff8c64514833b19796af171c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.033 >= min_delta = 0.0001. New best score: 0.370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90519c4025be45539abd34626bdbe454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.030 >= min_delta = 0.0001. New best score: 0.339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e49acc0b234ad6bc3d62036e8f74c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0001. New best score: 0.326\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714ad7d6090548efb8f0005511f7daeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0294c96749684e64896104b7e274da50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0001. New best score: 0.316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c3e4a62ccf4ccbb8cc06a06ca0061a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.008 >= min_delta = 0.0001. New best score: 0.308\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c26e37354cb44028806b8dfb8ad3d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2ad7c5bdf84e18b8315ef9dbcf1950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.016 >= min_delta = 0.0001. New best score: 0.292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3444cb2ec71e4259a3ec020764ecfc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0701a5bd7741f3b30cc4fbf80e797f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0001. New best score: 0.287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697e641f9edf4f69a9f526512dd70e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0001. New best score: 0.284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00de6c1c844a4578997c5147a97c4984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0001. New best score: 0.282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83358f09b07b43d0be10cfba97e5cb17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0001. New best score: 0.278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee86aeb606c456d8c22ee9d5dff52b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6219dc7dc89243e7a3f904ccb7a04ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae78991dbb07446699357eb0901bc768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0001. New best score: 0.274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8213098580bc4c57870f97b9f03407b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9629ae683bd24151b1f100e9b7e38d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0001. New best score: 0.270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f146f698fb649a1bd1d2abb9a0ea437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bf21d7d8954df0a89ace67bb10b224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f223699f03744813bf24a3e9fd453c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.270. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "trainer.fit(model, train_loader, test_loader)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "867675df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0 hours, 9 minutes, 39 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "elapsed_seconds = end_time - start_time\n",
    "hours = int(elapsed_seconds // 3600)\n",
    "minutes = int((elapsed_seconds % 3600) // 60)\n",
    "seconds = int(elapsed_seconds % 60)\n",
    "print(f\"Elapsed time: {hours} hours, {minutes} minutes, {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cc4d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_state_dict = model.state_dict()\n",
    "# def get_trained_model():\n",
    "#     \"\"\"\n",
    "#     Returns a fresh LightningModule loaded with trained weights,\n",
    "#     moved to eval() mode and CPU (or GPU if you .to(device) after).\n",
    "#     \"\"\"\n",
    "#     infer_model = MyANNLightning(\n",
    "#         num_features=model.hparams.num_features,\n",
    "#         num_cls=model.hparams.num_cls,\n",
    "#         lr=model.hparams.lr,\n",
    "#         weight_decay=model.hparams.weight_decay\n",
    "#     )\n",
    "#     infer_model.load_state_dict(trained_state_dict)\n",
    "#     infer_model.eval()\n",
    "#     return infer_model\n",
    "# infer_model = get_trained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0b0ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 10000\n",
      "Corrected: 8985\n",
      "Accuracy: 89.85\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for batch_features, batch_labels in test_loader:\n",
    "\n",
    "    batch_features, batch_labels = batch_features.to(device, non_blocking=True), batch_labels.to(device, non_blocking=True)\n",
    "\n",
    "    outputs = model(batch_features)\n",
    "    _, pred = torch.max(outputs, 1)\n",
    "    total += batch_labels.shape[0]\n",
    "    correct += (pred == batch_labels).sum().item()\n",
    "\n",
    "print(\"Total:\", total)\n",
    "print(\"Corrected:\", correct)\n",
    "print(\"Accuracy:\", (correct/total) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
